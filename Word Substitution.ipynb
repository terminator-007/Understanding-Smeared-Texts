{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "\n",
    "infile1 = open('dump_final.pkl','rb')\n",
    "lineList = pickle.load(infile1)\n",
    "infile1.close()\n",
    "\n",
    "corpus = '/home/varshini/Capstone/HTR/data/corpus.txt'\n",
    "with open(corpus, 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "blob = TextBlob(data)\n",
    "#nouns = blob.noun_phrases\n",
    "spell = SpellChecker() \n",
    "#with open('nouns.pkl', 'wb') as f:\n",
    "    #pickle.dump(nouns, f)\n",
    "    \n",
    "infile2 = open('/home/varshini/Capstone/nouns.pkl','rb')\n",
    "nouns = pickle.load(infile2)\n",
    "infile2.close()\n",
    "\n",
    "spell.word_frequency.load_text_file('/home/varshini/Capstone/HTR/data/corpus.txt')\n",
    "\n",
    "#To make sure some words are not flagged as misspelled\n",
    "spell.word_frequency.load_words(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineList1 = lineList\n",
    "\n",
    "def spellcheck(lineList1):\n",
    "    wordlist = lineList1.split()\n",
    "    misspelled = spell.unknown(wordlist)\n",
    "    for idx,value in enumerate(wordlist):\n",
    "        temp = \"\"\n",
    "        if value in misspelled:\n",
    "            value = value.lower()\n",
    "            #print(value)\n",
    "            # Get the one `most likely` answer\n",
    "            temp = temp.join(spell.correction(value))\n",
    "            wordlist[idx] = temp        \n",
    "    sentence = \" \"\n",
    "    return sentence.join(wordlist)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,line in enumerate(lineList1):\n",
    "    #lineList1[i] = (spellcheck(line))\n",
    "\n",
    "#with open('spellcheck.pkl', 'wb') as f:\n",
    "    #pickle.dump(lineList1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Since 1958 i3 Laboun Hfe Peeas and Peeresses have been conated Mast Labour sentiments would still the abolition the House Loads , but while it semains tabounr has to have ,u adegeate number of members . thewoo Gival Nationalist Parssties of Nonthe te exchaenge foom . the federal Prremie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since 1958 i3 Laboun Hfe Peeas and Peeresses have been conated Mast Labour sentiments would still the abolition the House Loads , but while it semains tabounr has to have ,u adegeate number of members . thewoo Gival Nationalist Parssties of Nonthe te exchaenge foom . the federal Prremie'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since 1958 in Laboun Hfe Peeas and Peeresses have been donated Mast Labour sentiments would still the abolition the House Loads , but while it remains labour has to have du adequate number of members . theo Gival Nationalist Parssties of Nonthe te exchange from . the federal Prremie'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellcheck(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Word -> i3\n",
      "Correction     -> in\n",
      "Incorrect Word -> conated\n",
      "Correction     -> donated\n",
      "Incorrect Word -> semains\n",
      "Correction     -> remains\n",
      "Incorrect Word -> tabounr\n",
      "Correction     -> labour\n",
      "Incorrect Word -> ,u\n",
      "Correction     -> du\n",
      "Incorrect Word -> adegeate\n",
      "Correction     -> adequate\n",
      "Incorrect Word -> thewoo\n",
      "Correction     -> theo\n",
      "Incorrect Word -> exchaenge\n",
      "Correction     -> exchange\n",
      "Incorrect Word -> foom\n",
      "Correction     -> from\n"
     ]
    }
   ],
   "source": [
    "wordlist = s.split()\n",
    "misspelled = spell.unknown(wordlist)\n",
    "for w in wordlist:\n",
    "    if w in misspelled:\n",
    "        w = w.lower()\n",
    "        print(\"Incorrect Word ->\",w)\n",
    "        print(\"Correction     ->\",spell.correction(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
